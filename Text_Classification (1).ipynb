{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UtigRF_3voP"
   },
   "source": [
    "\n",
    "#üèõÔ∏è Welcome to the NLP Challenge! ‚öñÔ∏èüöÄ\n",
    "Hey there, ML wizard! üßô‚Äç‚ôÇÔ∏è‚ú®\n",
    "<br><br>\n",
    "üîç Your Task: Predict the outcome of legal cases‚Äîmeaning how these cases will be referenced or used in future legal decisions‚Äîbased only on the case title and case text. üìú‚öñÔ∏è\n",
    "<br><br>\n",
    "What We're Looking For üëÄ\n",
    "This is not a leaderboard challenge! We're not just hunting for the highest accuracy score. Instead, we care about:\n",
    "- ‚úÖ Your approach ‚Äì How you analyze and structure the problem.\n",
    "- ‚úÖ Your creativity ‚Äì Can you think beyond the obvious solutions?\n",
    "- ‚úÖ Your rigor ‚Äì Thoughtful data preprocessing and model selection.\n",
    "- ‚úÖ Your reasoning ‚Äì Why did you pick a certain method? Explain it!\n",
    "\n",
    "If you use logistic regression, cool. If you dive into BERT embeddings, awesome. Just make sure you can explain your choices! üí°\n",
    "\n",
    "You have been provided with the `data` folder which contains:\n",
    "\n",
    "- `training.csv`: This contains labeled examples with case titles, case text, and their respective outcomes.\n",
    "- `test.csv`: This *contains* case titles and case text without labels. Your model must predict the case_outcome for each example.\n",
    "\n",
    "üìÇ Next Steps: Make a copy of this notebook, explore the data, build your model, and work your magic! üß†‚ú® Once you're done, submit the link to your completed notebook along with your `name_phonenumber_predictions.csv file`. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "do0f1kgAB2Br",
    "outputId": "3427e6e4-7327-4d5a-8935-b70e2771f499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _    _     _       _____ _   _ _____   ____  _____ ____ _____ \n",
      "   / \\  | |   | |     |_   _| | | | ____| | __ )| ____/ ___|_   _|\n",
      "  / _ \\ | |   | |       | | | |_| |  _|   |  _ \\|  _| \\___ \\ | |  \n",
      " / ___ \\| |___| |___    | | |  _  | |___  | |_) | |___ ___) || |  \n",
      "/_/   \\_\\_____|_____|   |_| |_| |_|_____| |____/|_____|____/ |_|  \n",
      "                                                                  \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lnW2qhd8tus"
   },
   "source": [
    "##1. Data Loading and Exploration\n",
    "- Read both training.csv and test.csv using Pandas.\n",
    "- Check for missing values, duplicates, and dataset statistics.\n",
    "- Perform basic text analysis (word count, distribution of labels, etc.).\n",
    "- Perform advanced analysis and report your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EXKu101r9BDz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Namrata.Paikekar\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Namrata.Paikekar\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data\\\\train.csv\")\n",
    "test_df = pd.read_csv(\"data\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "      <th>case_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re Lamb; Ex parte Registrar in Bankruptcy (198...</td>\n",
       "      <td>The following exchange took place on the first...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ogle v Strickland (1987) 13 FCR 306</td>\n",
       "      <td>Fourth, the respondent's submissions concernin...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walton v Gardiner [1993] HCA 77 ; (1993) 177 C...</td>\n",
       "      <td>First, in my opinion, to relitigate the events...</td>\n",
       "      <td>applied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stack &amp;amp; Anor v Elster Metering Pty Ltd &amp;am...</td>\n",
       "      <td>Stack and GST made a further application to th...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grant v Downs [1976] HCA 63 ; (1976) 135 CLR 674</td>\n",
       "      <td>was no great disagreement between counsel as t...</td>\n",
       "      <td>applied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          case_title  \\\n",
       "0  Re Lamb; Ex parte Registrar in Bankruptcy (198...   \n",
       "1                Ogle v Strickland (1987) 13 FCR 306   \n",
       "2  Walton v Gardiner [1993] HCA 77 ; (1993) 177 C...   \n",
       "3  Stack &amp; Anor v Elster Metering Pty Ltd &am...   \n",
       "4   Grant v Downs [1976] HCA 63 ; (1976) 135 CLR 674   \n",
       "\n",
       "                                           case_text case_outcome  \n",
       "0  The following exchange took place on the first...        cited  \n",
       "1  Fourth, the respondent's submissions concernin...        cited  \n",
       "2  First, in my opinion, to relitigate the events...      applied  \n",
       "3  Stack and GST made a further application to th...        cited  \n",
       "4  was no great disagreement between counsel as t...      applied  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Great Lakes Pty Ltd v K S Easter (Holdings...</td>\n",
       "      <td>In Air Great Lakes Pty Ltd v K S Easter (Holdi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          case_title  \\\n",
       "0  Air Great Lakes Pty Ltd v K S Easter (Holdings...   \n",
       "\n",
       "                                           case_text  \n",
       "0  In Air Great Lakes Pty Ltd v K S Easter (Holdi...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_outcome\n",
       "cited            9775\n",
       "referred to      3507\n",
       "applied          1959\n",
       "followed         1805\n",
       "considered       1370\n",
       "discussed         819\n",
       "distinguished     486\n",
       "related            90\n",
       "affirmed           90\n",
       "approved           87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['case_outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Minister relied on remarks of McHugh J in Re Minister for Immigration and Multicultural Affairs Ex parte Durairajasingham [2000] HCA 1 ; (2000) 74 ALJR 405 (and in particular I apprehend at 412-413 [35]-[36] and 416-418 [60]-[70]) that in effect the Tribunal in stating its reasons for decision was entitled to make findings of fact and was not required to go through line by line each item of evidence, or each relevant matter and deal with it in turn, accepting or dismissing it. So much may be accepted. The Minister also argued that the decision required under s 65 of the Migration Act 1958 (Cth) ('the Act') was whether or not the Tribunal, standing in the shoes of the Minister as the decision-maker, was satisfied of the matters set out in the Regulations for the purposes of granting the visa for which the appellant applied. She contended that findings along the way were not ones which went to jurisdiction. I am of opinion that it was not open to the Tribunal, on the basis only of the findings it set out, to find that a person in a single business that consists of running one retail trading shop who makes decisions daily about placing orders and pricing of goods offered for sale, and had done so for over one year prior to his application without any suggestion of supervision or control, did not have direct and continuous involvement in the management of that business from day to day or in making decisions that affect the overall direction and performance of that business. The Tribunal did not express any finding or reason for that ultimate conclusion, except that it did not find the evidence compelling. As McHugh J pointed out, in Minister for Immigration and Multicultural Affairs v Durairajasingham [2000] HCA 1 ; (2000) 74 ALJR 405 at 417 [70] the requirements of s 368 are that the Tribunal give a written but not lengthy explanation of the decision already made. I am of opinion that there was an absence of any reason, factual finding or reference to facts expressed in the Tribunal's reasons that could show that a person who had the duties and performed the functions of the appellant in the business during the period which the Tribunal was considering, namely the year prior to his visa application being lodged, did not satisfy the criteria of cl 845.216. Having regard to the Tribunal's expressed findings and reasons, its decision on this issue was so unreasonable that no reasonable decision-maker could have come to it on the basis expressed in those findings and reasons. That is not to say that another tribunal could not come to the same decision, but if it did so it would have to apply the law correctly, make findings and give reasons which were capable of supporting the decision. I can see no error of approach in the way that the Tribunal dealt with this matter. It was entitled to form a view as to whether or not what had been put to it by the appellant satisfied it as to the value of his assets. This was, as McHugh J said in the Minister for Immigration and Multicultural Affairs v Durairajasingham ((2000) 74 ALJR at 417 [67]) a finding on, inter alia, credibility or establishment of facts which was the function of a primary decision-maker par excellence. I do not consider that the Tribunal has been shown to have erred or not performed its function of review of the application in this respect. The question arises of how the matter ought then be resolved. The Minister has raised an issue of some difficulty. She says that the Tribunal may have erred in the way in which I have found, but that nonetheless even if one accepts that result, the application would be rejected on reconsideration by the Tribunal. That is because, even if the Tribunal formed a more favourable view on, first, the issue under cl 845.216 and then, secondly, on the language issue and awarded the appellant 10 more points, he would still be 10 points short of the 105 required to satisfy the points.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing sample data\n",
    "train_df['case_text'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19988, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4997, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_title      0.000000\n",
       "case_text       0.725435\n",
       "case_outcome    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df.isnull().sum()/train_df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can drop the missing values records as its is less than 1% \n",
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_title    0.000000\n",
       "case_text     0.620372\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df.isnull().sum()/test_df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarlly for test data also we can drop the missing values\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_title      object\n",
       "case_text       object\n",
       "case_outcome    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "      <th>case_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19843</td>\n",
       "      <td>19843</td>\n",
       "      <td>19843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>15254</td>\n",
       "      <td>15004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Minister for Immigration and Ethnic Affairs v ...</td>\n",
       "      <td>noted above, Comandate Marine's proceedings in...</td>\n",
       "      <td>cited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>9684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               case_title  \\\n",
       "count                                               19843   \n",
       "unique                                              15254   \n",
       "top     Minister for Immigration and Ethnic Affairs v ...   \n",
       "freq                                                   55   \n",
       "\n",
       "                                                case_text case_outcome  \n",
       "count                                               19843        19843  \n",
       "unique                                              15004           10  \n",
       "top     noted above, Comandate Marine's proceedings in...        cited  \n",
       "freq                                                   32         9684  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_df['case_outcome_encoded'] = encoder.fit_transform(train_df['case_outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_of_data = train_df['case_outcome_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAFzCAYAAAB8eic9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlQUlEQVR4nO3de7hkZX0n+u9PWhHkIkjDIBBhPIwGnERDx3uIUY+Sm5CMKHM0YHQOBy9RM1FHT+YYYh4STTLGaAKEGAWNI6Ax2ibR6OAFL3hpBLnKkQleiIy08YaXkIC/+aPelqJ77+7dzd67du/+fJ6nnlr11rtWveuttVbtb6231q7uDgAAANxt1g0AAABgZRAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGNbMugHL7YADDujDDz981s0AAACYiUsvvfRr3b12rud2uYB4+OGHZ8OGDbNuBgAAwExU1Rfne84QUwAAAJIsYUCsqjdU1c1VddVU2f5V9f6q+vy432/quZdV1fVVdV1VPXGq/JiqunI899qqqlG+e1VdMMo/WVWHL9W6AAAA7AqW8gziuUmO26zspUku6u4jk1w0HqeqjkpyUpKjxzxnVtVuY56zkpya5Mhx27TMZyX5Rnf/H0n+KMmrlmxNAAAAdgFLFhC7++IkX9+s+Pgk543p85KcMFV+fnff2t03JLk+yUOr6uAk+3T3Jd3dSd602TyblvX2JI/bdHYRAACA7bfcv0E8qLtvSpJxf+AoPyTJl6fq3TjKDhnTm5ffaZ7uvi3Jt5LcZ64XrapTq2pDVW3YuHHjIq0KAADA6rJSLlIz15m/3kr51ubZsrD7nO5e193r1q6d82quAAAAu7zlDohfHcNGM+5vHuU3Jjlsqt6hSb4yyg+do/xO81TVmiT7ZsshrQAAACzQcgfE9UlOGdOnJHnXVPlJ48qkR2RyMZpPjWGot1TVw8fvC0/ebJ5Ny3pykg+M3ykCAACwA9Ys1YKr6q1JHpPkgKq6MclvJXllkgur6llJvpTkxCTp7qur6sIk1yS5Lclzu/v2sahnZ3JF1D2SvGfckuQvkry5qq7P5MzhSUu1LgAAALuC2tVOuq1bt643bNgw62YAAADMRFVd2t3r5npupVykBgAAgBkTEAEAAEgiIAIAADAIiAAAACRZwquY7qw2PP+0WTdhxVj32rNn3QQAAGAZOYMIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAYSYBsap+vaqurqqrquqtVXXPqtq/qt5fVZ8f9/tN1X9ZVV1fVddV1ROnyo+pqivHc6+tqprF+gAAAKwGyx4Qq+qQJM9Psq67H5RktyQnJXlpkou6+8gkF43HqaqjxvNHJzkuyZlVtdtY3FlJTk1y5Lgdt4yrAgAAsKrMaojpmiR7VNWaJHsm+UqS45OcN54/L8kJY/r4JOd3963dfUOS65M8tKoOTrJPd1/S3Z3kTVPzAAAAsJ2WPSB29z8m+cMkX0pyU5Jvdff7khzU3TeNOjclOXDMckiSL08t4sZRdsiY3rx8C1V1alVtqKoNGzduXMzVAQAAWDVmMcR0v0zOCh6R5L5J7lVVT9/aLHOU9VbKtyzsPqe713X3urVr125vkwEAAHYJsxhi+vgkN3T3xu7+1yTvSPLIJF8dw0Yz7m8e9W9MctjU/IdmMiT1xjG9eTkAAAA7YBYB8UtJHl5Ve46rjj4uybVJ1ic5ZdQ5Jcm7xvT6JCdV1e5VdUQmF6P51BiGektVPXws5+SpeQAAANhOa5b7Bbv7k1X19iSfSXJbksuSnJNkryQXVtWzMgmRJ476V1fVhUmuGfWf2923j8U9O8m5SfZI8p5xAwAAYAcse0BMku7+rSS/tVnxrZmcTZyr/hlJzpijfEOSBy16AwEAAHZBs/o3FwAAAKwwAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBhJgGxqu5dVW+vqs9V1bVV9Yiq2r+q3l9Vnx/3+03Vf1lVXV9V11XVE6fKj6mqK8dzr62qmsX6AAAArAazOoP4x0ne290PTPLjSa5N8tIkF3X3kUkuGo9TVUclOSnJ0UmOS3JmVe02lnNWklOTHDluxy3nSgAAAKwmyx4Qq2qfJMcm+Ysk6e5/6e5vJjk+yXmj2nlJThjTxyc5v7tv7e4bklyf5KFVdXCSfbr7ku7uJG+amgcAAIDtNIsziP82ycYkb6yqy6rq9VV1ryQHdfdNSTLuDxz1D0ny5an5bxxlh4zpzcu3UFWnVtWGqtqwcePGxV0bAACAVWIWAXFNkp9IclZ3PyTJdzOGk85jrt8V9lbKtyzsPqe713X3urVr125vewEAAHYJswiINya5sbs/OR6/PZPA+NUxbDTj/uap+odNzX9okq+M8kPnKAcAAGAHLHtA7O7/leTLVfWAUfS4JNckWZ/klFF2SpJ3jen1SU6qqt2r6ohMLkbzqTEM9Zaqevi4eunJU/MAAACwndbM6HV/LclbquoeSf4hya9mElYvrKpnJflSkhOTpLuvrqoLMwmRtyV5bnffPpbz7CTnJtkjyXvGDQAAgB0wk4DY3ZcnWTfHU4+bp/4ZSc6Yo3xDkgctauMAAAB2UbP6P4gAAACsMAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIssCAWFUXLaQMAACAndearT1ZVfdMsmeSA6pqvyQ1ntonyX2XuG0AAAAso60GxCT/T5IXZhIGL80dAfHbSf506ZoFAADActtqQOzuP07yx1X1a939umVqEwAAADOwrTOISZLufl1VPTLJ4dPzdPeblqhdAAAALLMFBcSqenOS+ye5PMnto7iTCIgAAACrxIICYpJ1SY7q7l7KxgAAADA7C/0/iFcl+TdL2RAAAABma6FnEA9Ick1VfSrJrZsKu/tJS9IqAAAAlt1CA+LpS9kIAAAAZm+hVzH98FI3BAAAgNla6FVMb8nkqqVJco8kd0/y3e7eZ6kaBgAAwPJa6BnEvacfV9UJSR66FA0CAABgNhZ6FdM76e53Jnns4jYFAACAWVroENNfnnp4t0z+L6L/iQgAALCKLPQqpr84NX1bki8kOX7RWwMAAMDMLPQ3iL+61A0BAABgthb0G8SqOrSq/rqqbq6qr1bVX1XVoUvdOAAAAJbPQi9S88Yk65PcN8khSd49ygAAAFglFhoQ13b3G7v7tnE7N8naJWwXAAAAy2yhAfFrVfX0qtpt3J6e5J+WsmEAAAAsr4UGxGcmeUqS/5XkpiRPTuLCNQAAAKvIQv/Nxe8kOaW7v5EkVbV/kj/MJDgCAACwCiz0DOKPbQqHSdLdX0/ykKVpEgAAALOw0IB4t6rab9ODcQZxoWcfAQAA2AksNOT9tyQfr6q3J+lMfo94xpK1CgAAgGW3oIDY3W+qqg1JHpukkvxyd1+zpC0DAABgWS14mOgIhEIhAADAKrXQ3yACAACwygmIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgmFlArKrdquqyqvqb8Xj/qnp/VX1+3O83VfdlVXV9VV1XVU+cKj+mqq4cz722qmoW6wIAALAazPIM4guSXDv1+KVJLuruI5NcNB6nqo5KclKSo5Mcl+TMqtptzHNWklOTHDluxy1P0wEAAFafmQTEqjo0yc8nef1U8fFJzhvT5yU5Yar8/O6+tbtvSHJ9kodW1cFJ9unuS7q7k7xpah4AAAC206zOIL4myUuS/GCq7KDuvilJxv2Bo/yQJF+eqnfjKDtkTG9evoWqOrWqNlTVho0bNy7KCgAAAKw2yx4Qq+oXktzc3ZcudJY5ynor5VsWdp/T3eu6e93atWsX+LIAAAC7ljUzeM1HJXlSVf1cknsm2aeq/jLJV6vq4O6+aQwfvXnUvzHJYVPzH5rkK6P80DnKAQAA2AHLfgaxu1/W3Yd29+GZXHzmA9399CTrk5wyqp2S5F1jen2Sk6pq96o6IpOL0XxqDEO9paoePq5eevLUPAAAAGynWZxBnM8rk1xYVc9K8qUkJyZJd19dVRcmuSbJbUme2923j3meneTcJHskec+4AQAAsANmGhC7+0NJPjSm/ynJ4+apd0aSM+Yo35DkQUvXQgAAgF3HLP8PIgAAACuIgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACRJ1sy6AcDCrd9w2qybsGI8ad3Zs24CAMCq4wwiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMCx7QKyqw6rqg1V1bVVdXVUvGOX7V9X7q+rz436/qXleVlXXV9V1VfXEqfJjqurK8dxrq6qWe30AAABWi1mcQbwtyW90948meXiS51bVUUlemuSi7j4yyUXjccZzJyU5OslxSc6sqt3Gss5KcmqSI8ftuOVcEQAAgNVk2QNid9/U3Z8Z07ckuTbJIUmOT3LeqHZekhPG9PFJzu/uW7v7hiTXJ3loVR2cZJ/uvqS7O8mbpuYBAABgO830N4hVdXiShyT5ZJKDuvumZBIikxw4qh2S5MtTs904yg4Z05uXz/U6p1bVhqrasHHjxkVdBwAAgNViZgGxqvZK8ldJXtjd395a1TnKeivlWxZ2n9Pd67p73dq1a7e/sQAAALuANbN40aq6eybh8C3d/Y5R/NWqOri7bxrDR28e5TcmOWxq9kOTfGWUHzpHOSvIhgtPm3UTVox1Tzl71k0AAICtmsVVTCvJXyS5trtfPfXU+iSnjOlTkrxrqvykqtq9qo7I5GI0nxrDUG+pqoePZZ48NQ8AAADbaRZnEB+V5FeSXFlVl4+y/zfJK5NcWFXPSvKlJCcmSXdfXVUXJrkmkyugPre7bx/zPTvJuUn2SPKecQMAAGAHLHtA7O6PZu7fDybJ4+aZ54wkZ8xRviHJgxavdQAAALuumV7FFAAAgJVjJhepAQDmd9rHN8y6CSvG2Y9cN+smAOxSnEEEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkyZpZNwCAnd9pG86cdRNWjLPXPWfWTQCAHeYMIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADGtm3QAAgKV02u9vmHUTVoyzX7Ju1k0AVjhnEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAMOaWTcAYFZesuG0WTdhxfj9dWfPugkAwArgDCIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEiyCgJiVR1XVddV1fVV9dJZtwcAAGBntWbWDbgrqmq3JH+a5P9McmOST1fV+u6+ZrYtAwBYfV5x2oZZN2HFePnZ6+7yMj6gP3/osYvQnxtOe8MitGR1WHf2M3d43p39DOJDk1zf3f/Q3f+S5Pwkx8+4TQAAADul6u5Zt2GHVdWTkxzX3f9pPP6VJA/r7udtVu/UJKeOhw9Ict2yNnTHHJDka7NuxCqiPxePvlxc+nNx6c/Foy8Xl/5cXPpzcenPxbOz9OX9unvtXE/s1ENMk9QcZVsk3u4+J8k5S9+cxVNVG7r7rp9rJ4n+XEz6cnHpz8WlPxePvlxc+nNx6c/FpT8Xz2roy519iOmNSQ6benxokq/MqC0AAAA7tZ09IH46yZFVdURV3SPJSUnWz7hNAAAAO6Wdeohpd99WVc9L8vdJdkvyhu6+esbNWiw71ZDYnYD+XDz6cnHpz8WlPxePvlxc+nNx6c/FpT8Xz07flzv1RWoAAABYPDv7EFMAAAAWiYAIAABAEgFxpqrqtKo6eUw/o6ruu53zH15VVy1N61aX0b9/MqZ/2O/bMf93lqZls1FVz6+qa6vqLcvwWh+qqi0u91xVL6yqPZf69bdHVZ1eVS+qqldU1eO3Uu+Eqjpq6vFW69+F9myrHeeO/we7o8s/vapetKPzrwRV9XdVde85ypds3Vby8WBb+/Zmx8Jle/+r6gtVdcByvNZiWejxYNZWw368UqzkfXsxbGv9qureVfWcHVjuqtwGq+rEcTz94Hj81qq6oqp+fbmOC7Pq2536IjU7u+4+e+rhM5JcFf+mY8lt1u+rUlVVJr8x/sE8VZ6T5Ge7+4YFLm9Nd9823+Md9MIkf5nke3dxOYuuu1++jSonJPmbJNcssP5StWOX190/txjLWaRteiXYrn2bbbMfriyraF9dEgv4/N+ae2dyDDlzURu183pWkud09wer6t8keWR3329rM1TVbt19+/I0b+k4g7iMqurk8c3DZ6vqzVPfTj45ybokb6mqy6tqj6o6pqo+XFWXVtXfV9XBYxnHjPkvSfLcma7QMqmqd45+uLqqTh1l36mq/1ZVn6mqi6pq7Sj/UFW9pqo+XlVXVdVD51jeD7+Nqar7V9V7x/I/UlUPHOVHVNUlVfXpqvqd5VzfHTXOKF9bVWcm+UySw6rqxWMdrqiq3x71zk7yb5OsH9+C3auq3jDqXVZVx496z6iqt1XVu5O8b47H8823R1WdP17zgiR7zNHW5ye5b5IPTn0z9x+r6srxvr1qGbpsU1t+s6quq6r/keQBo+yHZ+aq6pVVdc1Ynz+sqkcmeVKSPxj76/03q/+FqvrtsW1eObVNra2q94/yP6uqL1bVAbXZSIBxTDh9W+2YWoVjx/b+DzV1NnGu936+9V0OteXx735j371i3P/I1Dq/dvN1qqqDq+ri0edXVdVPjfIfnpmab922sp+fW1WvHtvgq3b248Fm+/Zv1OTYeUVVfaKqfmwb8z541Luiqv66qvarqgOr6tLx/I9XVU+9T/+zqvYc2/Vfjb75dFU9ajx/n6p63zg2/FmSWuLVXxTbezwYZQeNPvvsuD1yG/v186eWcf4o++mxbV8++mzvUb6i9uMdUYvwGV6Tz+1zqup9Sd401/GjqvYdx4O7jXn2rKovV9Xdd/Z9e1tqy8///2+u7Waq/l6j3zZ9Th0/nnplkvuP7fAPRt2dfhtciM2306p6eZJHJzl79MX7khw4+uanasvP/ZdX1UeTnDge/+7YtjZU1U/U5G/5/1lVp0295srt2+52W4ZbkqOTXJfkgPF4/ySnJ3nRePyhJOvG9N2TfDzJ2vH4qZn8C48kuSLJT4/pP0hy1azXbRn6bv9xv0cmZ1nvk6STPG2UvzzJn0z145+P6WM39U8mZ2g31Znu94uSHDmmH5bkA2N6fZKTx/Rzk3xn1v2wgH46PMkPkjx8PH5CJpdarky+DPqbJMeO574wtS3+bpKnj+l7J/n/k9xr9NmNU/2/+eP55vvPU9vrjyW5bdO2vVl7p9tw3yRfSrI2k5ENH0hywjL02TFJrkyyZ5J9klyf5EVJzk3y5LGfXpc7rvh873F/bpInTy3nh4/Hev3amH5OkteP6T9J8rIxfdzYhg8Y79tVU8t6UZLTp5e7jXa8bby/RyW5fmvv/Xzruwz9PNfx791JThmPn5nkndtYp99I8ptjercke09vR1tbt8y/n587+ma3bdTbaY4HU/3xuiS/Ncoem+Tyqf14rmPh9GfLK5K8ZkxfPfrzeZn87+GnJblfkkvG8/89yaPH9I8kuXZMvzbJy8f0z2ds77Pun2303Y4eDy5I8sKpbXPfbH2//kqS3TdbxruTPGpM75XJcXBF7cd3oV8X4zP89CSXJtljqr9OGdPTx493JfmZMf3U3HH83en37W308eEZn//zbTej3nfG/Zok+4zpA8Y2VHNst6tiG7wL2+mHcsff5pv3zbm58+f+S6ae+0KSZ4/pP8rk+Lp3Jn/j3Lwz9K0hpsvnsUne3t1fS5Lu/nrVvF+oPiDJg5K8f9TZLclNVbVvJh8mHx713pzkZ5e01SvD86vql8b0YUmOzORAeMEo+8sk75iq/9Yk6e6Lq2qfmuP3ScnkG7Qkj0zytqn3Yvdx/6gk/2FMvznJsp3Ruou+2N2fGNNPGLfLxuO9Mum7izeb5wlJnlR3jHG/ZyZ/6CXJ+7v761N1px/PN9+xmfxxmO6+oqquWEC7fzLJh7p7Y5LU5PdTxyZ55wLmvSt+Kslfd/f3xuuu3+z5byf55ySvr6q/zeQAvhCbtsdLk/zymH50kl9Kku5+b1V9YzvaubV2vLMnQ4muqaqDRtl87/3e2fr6LpW5jn+PyB198+Ykvz9Vf651+nSSN1TV3cfzl2/2GnO+l9vYz5Pkbd19+yo8Hjw6o83d/YGanNHbd66Kc3y2nJdJSE8mX1Y+KpP98Xcz+XKjknxkPP/4JEdN9dk+4+zXsRnvb3f/7XZu77Oyo8eDxyY5OUl6MrTsW1W131Ze54pMRgy9M3cc4z6W5NXj2PeO7r6xqlbafryjFuszfH13f39Mz3f8uCCTYPjBJCclOXMV7tvz+WJ3f6ImZ7a39dlfSX63qo7N5L04JMlB2dJq2QYXYq7tdHtcsNnjTX1yZZK9uvuWJLdU1T+PbXpF962AuHwqk2/MFlr36u5+xJ0KJxvUQpexKlTVYzL5A+QR3f29qvpQJkFkcz3P9FyPN7lbkm9294PneX5n7OvvTk1Xkt/r7j/bxjyV5D9093V3Kqx62GbLm2v5c82XbH/fzXL42bxt7e7bajLE6XGZ/LHxvEz+GNyWW8f97bnjODvfOt6WOw/332L73kY7bp2qWlP3W7z3VfXCzGa7Xsjxb/r5LdZp/LF4bCZno95cVX/Q3W/ayjI22dZ+/t0F1tvZjgdzbW87sg4fySQ43S+TszP/ZSxnUzi6WybH5+9Pz7SDx4GVYLGOB1vbr38+kwD9pEyGAh7d3a8cofPnknyiJhe/WGn78XZb5M/wzT+P5qqzPsnvVdX+mZyJ+UAmI1tW0749n039s5DP/qdlcjbrmO7+16r6QuZ+X3b6bXAhtmM73ZrNt89Nn2M/yJ0/036Qyd8FK7pv/QZx+VyU5ClVdZ8kGQevabdk8q1BMhnCsnZ8w56ajJ8/uru/mck3k48e9Z629M2euX2TfGPssA/MZPhEMtl2N/3e6v9K8tGpeZ6aJKOfvtXd35prwd397SQ3VNWJo35V1Y+Ppz+WyR8Ayc7bz3+f5Jnj29NU1SFVdeA89X6txl90VfWQ7Vj+XPNdnNFnVfWgTIaZzmV6m/9kkp+uyW/ydkvyH5N8eJ75FtPFSX6pJr+b3DvJL04/Ofpu3+7+u0wuqvPgOdq+UB9N8pSx3Cck2XSG4auZ/K7hPlW1e5Jf2HzGrbRjPvO991td3yU01/Hv47nzPvbReebNmOd+mQzN+fMkf5HkJzarMue6bWM//6FVeDyY3g8fk+RrYx23MI6R36jxu84kv5I79r+Lkzw9yefHWd2vZxJiPjaef18mQSnjtR48x+v/bO7Y3leyHT0eXJTk2aPOblW1T+bZr2vy+7jDuvuDSV6SyfD8varq/t19ZXe/KsmGJA/MytuPd8RSfYbPefzo7u8k+VSSP07yN919+yrct7dlIZ/9+2ZyPP3XqvqZTL4ASrb8bFsN2+BCzLedLqUV3bfOIC6T7r66qs5I8uGquj2TU8pfmKpybiY/hP1+JkMnnpzktTUZ+rMmyWsy+S3Ir2YyzOp7mWxcq917k5xWk2GK1yXZNHzyu0mOrskFFL6V8YEyfKOqPp7J2O1nbmP5T0tyVlX910x++3l+ks8meUGS/15VL0jyV4u1Msupu99XVT+a5JKR4b6TyR96N29W9Xcy2b6uGGHvC5kjpMxhvvnOSvLG8Z5dnsmH9VzOSfKeqrqpu3+mql6WybCgSvJ33f2uBa3oXdDdn6nJhXQuT/LF3DFsbpO9k7yrqu452vXro/z8JH9ek4vtLPTfTPx2krdW1VMz+eP7piS3jA/oV2QSkm9I8rk55p2vHfOt15zv/QLWd0nMc/x7fibHshcn2ZjJsW1rHpPkxVX1r5msz53+Vc021m2+/Xxzq+l4cHru2A+/l+SUbdQ/JZPPoD2T/EPG+9HdXxjb0KbhaR9Ncmh3bxoy+vwkfzpeZ82od1ru2N4/k8n2/qVFWq8lcxeOBy9Ick5VPSuTUQPP7u5L5tmvd0vyl+OzvZL8UXd/s6p+Z/yhfnsmV0d+T3ffupL24x20VJ/hWzt+XJDJEOnHTJWtpn17qxb42f+WJO+uqg2ZbEefG/P+U1V9rCYXWHpPd794FWyDCzHfdrpkVtrn9OY2/dAadipV9Z3u3muO8g9l8mPeDcvfKpjfOItw+xim9ogkZ21lyBPAquUzHFY2ZxABlsePJLlwDDH7lyT/94zbAwCwBWcQAQAASOIiNQAAAAwCIgAAAEkERAAAAAYBEQBmrKqeUVX3nXU7AEBABIDZe0YSARGAmRMQAdglVNXJVXVFVX22qt5cVb9YVZ+sqsuq6n9U1UGj3k9X1eXjdllV7T3KX1xVnx7L+O1tvNZ/rqqrxu2Fo+zw8Q+oN9V5UVWdXlVPTrIuyVvGa+5RVT9ZVR8fbf1UVe1dVfesqjdW1ZWjXT8zlvOMqnpnVb27qm6oqueN17+sqj5RVfuPevevqvdW1aVV9ZGqeuCSdDQAOzX/BxGAVa+qjk7ym0ke1d1fG6Gpkzy8u7uq/lOSlyT5jSQvSvLc7v5YVe2V5J+r6glJjkzy0CSVZH1VHdvdF8/xWsck+dUkDxt1P1lVH07yjbna1t1vr6rnZfyD8Kq6R5ILkjy1uz9dVfsk+X6SF4z6/36Eu/dV1b8bi3lQkockuWeS65P8l+5+SFX9UZKTk7wmyTlJTuvuz1fVw5KcmeSxO9qnAKxOAiIAu4LHJnl7d38tSbr761X175NcUFUHJ7lHkhtG3Y8leXVVvSXJO7r7xhEQn5DkslFnr0wC4xYBMcmjk/x1d383SarqHUl+Ksn6Bbb1AUlu6u5Pj7Z+eyzn0UleN8o+V1VfTLIpIH6wu29JcktVfSvJu0f5lUl+bATdRyZ5W1Vtep3dF9geAHYhAiIAu4LK5IzhtNcleXV3r6+qxyQ5PUm6+5VV9bdJfi7JJ6rq8WP+3+vuP1vga83lttz5px333I62bm25SXLr1PQPph7/IJPP+rsl+WZ3P3grywAAv0EEYJdwUZKnVNV9kmQMMd03yT+O50/ZVLGq7t/dV3b3q5JsSPLAJH+f5JnjTFyq6pCqOnCe17o4yQlVtWdV3SvJLyX5SJKvJjmwqu5TVbsn+YWpeW5JsveY/lyS+1bVT47X2ruq1ozlPm2U/bskP5LkuoWs/DgLeUNVnTjmr6r68YXMC8CuxRlEAFa97r66qs5I8uGquj2ToaKnZzLk8h+TfCLJEaP6C8cFYG5Pck2S93T3rVX1o0kuGUM0v5Pk6UlunuO1PlNV5yb51Ch6fXdfliRV9Yokn8xkOOvnpmY7N8nZVfX9JI9I8tQkr6uqPTL5/eHjM/nN4NlVdWUmZyOfMdq10G54WpKzquq/Jrl7kvOTfHahMwOwa6juuUaxAAAAsKsxxBQAAIAkhpgCwA4Zv2e8aI6nHtfd/7Tc7QGAxWCIKQAAAEkMMQUAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABj+NzbHtvmCZwjIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.countplot(train_df['case_outcome'], data=train_df, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for basic preprocessing \n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    return text.strip()\n",
    "\n",
    "# apply function to textual columns\n",
    "train_df['case_text'] = train_df['case_text'].apply(lambda x:clean_text(x))\n",
    "train_df['case_title'] = train_df['case_title'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "train_df['case_text'] = train_df['case_text'].apply(lambda x:remove_punctuation(x))\n",
    "train_df['case_title'] = train_df['case_title'].apply(lambda x:remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output = \" \".join(word for word in text.split() if word.lower() not in stopwords)\n",
    "    return output\n",
    "\n",
    "# Apply tokenization to the 'case_text' column\n",
    "train_df['case_text'] = train_df['case_text'].apply(lambda x:remove_stopwords(x))\n",
    "train_df['case_title'] = train_df['case_title'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize the text\n",
    "def lemmatizer_func(text):\n",
    "    lemm_text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return lemm_text\n",
    "\n",
    "# Apply lemmatization to the 'case_text' column\n",
    "train_df['case_text'] = train_df['case_text'].apply(lemmatizer_func)\n",
    "train_df['case_title'] = train_df['case_title'].apply(lemmatizer_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_outcome_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lamb ex parte registrar bankruptcy 1984 1 fcr 391</td>\n",
       "      <td>following exchange took place first three day ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ogle v strickland 1987 13 fcr 306</td>\n",
       "      <td>fourth respondent submission concerning issue ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walton v gardiner 1993 hca 77 1993 177 clr 378</td>\n",
       "      <td>first opinion relitigate event 27 march 2006 a...</td>\n",
       "      <td>applied</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stack amp anor v elster metering pty ltd amp o...</td>\n",
       "      <td>stack gst made application high court special ...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grant v down 1976 hca 63 1976 135 clr 674</td>\n",
       "      <td>great disagreement counsel principle applied m...</td>\n",
       "      <td>applied</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          case_title  \\\n",
       "0  lamb ex parte registrar bankruptcy 1984 1 fcr 391   \n",
       "1                  ogle v strickland 1987 13 fcr 306   \n",
       "2     walton v gardiner 1993 hca 77 1993 177 clr 378   \n",
       "3  stack amp anor v elster metering pty ltd amp o...   \n",
       "4          grant v down 1976 hca 63 1976 135 clr 674   \n",
       "\n",
       "                                           case_text case_outcome  \\\n",
       "0  following exchange took place first three day ...        cited   \n",
       "1  fourth respondent submission concerning issue ...        cited   \n",
       "2  first opinion relitigate event 27 march 2006 a...      applied   \n",
       "3  stack gst made application high court special ...        cited   \n",
       "4  great disagreement counsel principle applied m...      applied   \n",
       "\n",
       "   case_outcome_encoded  \n",
       "0                     3  \n",
       "1                     3  \n",
       "2                     1  \n",
       "3                     3  \n",
       "4                     1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('v', 69045), ('court', 46249), ('ltd', 36017), ('j', 32839), ('act', 27036), ('case', 27024), ('pty', 25012), ('applicant', 24390), ('tribunal', 22083), ('decision', 20308)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocess: Tokenize, convert to lowercase, and remove non-alphabetic characters\n",
    "words = train_df['case_text'].apply(lambda x: re.findall(r'\\b\\w+\\b', str(x).lower()))  # Apply on each row\n",
    "\n",
    "# Flatten the list of words (because 'words' is a list of lists now)\n",
    "flat_words = [word for sublist in words for word in sublist]\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(flat_words)\n",
    "\n",
    "# Display the most common words\n",
    "print(word_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_outcome_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>polyaire pty ltd v kaire pty ltd others 2005 h...</td>\n",
       "      <td>even wrong view seems test fraudulent imitatio...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15458</th>\n",
       "      <td>australian competition consumer commission v n...</td>\n",
       "      <td>9 may 2007 ryan j made order granting injuncti...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8425</th>\n",
       "      <td>meridian global fund management asia ltd v sec...</td>\n",
       "      <td>circumstance present case 826 operate technica...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>southern cross interior pty ltd v deputy commi...</td>\n",
       "      <td>relevant principle distilled palmer j southern...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18453</th>\n",
       "      <td>brock v united state america 2007 fcafc 3 2007...</td>\n",
       "      <td>211 relevantly provides within 15 day magistra...</td>\n",
       "      <td>cited</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              case_title  \\\n",
       "854    polyaire pty ltd v kaire pty ltd others 2005 h...   \n",
       "15458  australian competition consumer commission v n...   \n",
       "8425   meridian global fund management asia ltd v sec...   \n",
       "1834   southern cross interior pty ltd v deputy commi...   \n",
       "18453  brock v united state america 2007 fcafc 3 2007...   \n",
       "\n",
       "                                               case_text case_outcome  \\\n",
       "854    even wrong view seems test fraudulent imitatio...        cited   \n",
       "15458  9 may 2007 ryan j made order granting injuncti...        cited   \n",
       "8425   circumstance present case 826 operate technica...        cited   \n",
       "1834   relevant principle distilled palmer j southern...        cited   \n",
       "18453  211 relevantly provides within 15 day magistra...        cited   \n",
       "\n",
       "       case_outcome_encoded  \n",
       "854                       3  \n",
       "15458                     3  \n",
       "8425                      3  \n",
       "1834                      3  \n",
       "18453                     3  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling:\n",
      " case_outcome_encoded\n",
      "0    7747\n",
      "1    7747\n",
      "2    7747\n",
      "3    7747\n",
      "4    7747\n",
      "5    7747\n",
      "6    7747\n",
      "7    7747\n",
      "8    7747\n",
      "9    7747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['case_outcome_encoded'], random_state=42)\n",
    "\n",
    "majority_class_size = train_df['case_outcome_encoded'].value_counts().max()\n",
    "train_df_balanced = train_df.groupby('case_outcome_encoded', group_keys=False) \\\n",
    "                            .apply(lambda x: x.sample(majority_class_size, replace=True)).reset_index(drop=True)\n",
    "\n",
    "balanced_class_counts = train_df_balanced['case_outcome_encoded'].value_counts()\n",
    "print(\"Class distribution after oversampling:\\n\", balanced_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom Dataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class LegalDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length, stride):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        case_text = str(self.data.iloc[index]['case_text'])\n",
    "        case_outcome = self.data.iloc[index]['case_outcome_encoded']\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            case_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(case_outcome, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09e5921cee14c8995682e9ac39d1b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a1fafcdfed4229a471cfea92b00ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model and tokenizer intialization\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "legalbert_model_name = 'nlpaueb/legal-bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(legalbert_model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(legalbert_model_name, num_labels=len(encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup\n",
    "\n",
    "max_length = 256\n",
    "stride = 64\n",
    "batch_size = 16\n",
    "epochs = 6\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset and Dataloader\n",
    "\n",
    "train_dataset = LegalDataset(train_df_balanced, tokenizer, max_length, stride)\n",
    "val_dataset = LegalDataset(val_df, tokenizer, max_length, stride)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class weights\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_df_balanced['case_outcome_encoded']),\n",
    "                                     y=train_df_balanced['case_outcome_encoded'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training schedular \n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        labels = d['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "    return correct_predictions / len(data_loader.dataset), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    y_preds = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader):\n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "            labels = d['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "            y_preds.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    return correct_predictions / len(data_loader.dataset), np.mean(losses), y_true, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 3012/4842 [17:04:55<10:20:45, 20.35s/it]"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
    "    print(f'Train loss: {train_loss:.3f}, accuracy: {train_acc:.3f}')\n",
    "    val_acc, val_loss, y_true, y_preds = eval_model(model, val_loader, device)\n",
    "    print(f'Validation loss: {val_loss:.3f}, accuracy: {val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ0LnE1-9BfE"
   },
   "source": [
    "##2. Model Training\n",
    "- Choose an appropriate baseline model.\n",
    "- Experiment with Advanced models. Deep Learning models like (LSTMs, Transformers (BERT, RoBERTa)) are optional .\n",
    "- Fine-tune hyperparameters to optimize performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWsnPh3t9PNP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUMgA5Jy9PcA"
   },
   "source": [
    "##3. Model Evaluation\n",
    "- Use a validation split or cross-validation.\n",
    "- Report accuracy, precision, recall, F1-score.\n",
    "- Display a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaYjP2vU9Uw-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5yPD-wY9VTs"
   },
   "source": [
    "##4. Generate Predictions\n",
    "Predict the case_outcome for each entry in test.csv.\n",
    "\n",
    "Save predictions in `name_phonenumber_predictions.csv` with the correct format:\n",
    "```\n",
    "applied\n",
    "cited\n",
    "cited\n",
    "...\n",
    "```\n",
    "\n",
    "Please submit the link to the colab notebook with the outputs intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De9CnSOCAsbN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
